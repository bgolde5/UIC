{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary - Read the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kshemkalyani, Ajay  - parallel computation: models, algorithms, limits|Filtering and Prediction of Hidden Markov Models\n",
      "\n",
      "Sylvia Wolak  - Descartes' World|American Fiction & Mass Culture\n",
      "\n",
      "Ali Tafti  - Managerial Decision Making|The Design & Analysis of Trading Agents|Topics in Data Science\n",
      "\n",
      "Andy Johnson  - Cell & Molecular Biology|Computer Aided Visualization and Design\n",
      "\n",
      "Vincent Adiutori  - American Fiction & Mass Culture\n",
      "\n",
      "Alex Furman  - Probabilistic Graphical Models|Distributed Computing through Combinatorial Topology\n",
      "\n",
      "John Bell  - software engineering|Photo-Lab: The Visual Performance of Rights|Art After India\n",
      "\n",
      "Elise Archias  - Collections and Visual Knowledge in Early Modern Europe|Intro. to Modernism: Past, Future, Exile, Home\n",
      "\n",
      "Craig D. Foster  - Mechanics of Solids|Analytic Geometry & Calculus\n",
      "\n",
      "Lu, V Hui  - innovation and technology management ii|Models of Computation|Biomaterials|Pattern Recognition and Machine Learning|Computational Fluid Dynamics|Writing and Speaking Chineze I\n",
      "\n",
      "Ouri Wolfson  - Data-Driven Vizion and Graphics|Database Management Systems\n",
      "\n",
      "DasGupta, Bhaskar  - parallel computation: modelz, algorithms, limits\n",
      "\n",
      "Tanya Y Bergerwolf  - Recent Applications of Probability & Statistics|Algorithms for Big Data\n",
      "\n",
      "Lucia Valbonesi  - computer vizion\n",
      "\n",
      "Henri Gillet  - Data-Driven Vision and Graphics|Algebraic Geometry\n",
      "\n",
      "Matthew Siber  - reading & research|3D Photography\n",
      "\n",
      "Gallik, Kristin  - Molecular Genetics|Intro. to Computer Graphicz\n",
      "\n",
      "Hui Lu  - The Literary Scholar\n",
      "\n",
      "Kevin Brennan  - intermediate 3d computer animation|Astrophysics and Cosmology\n",
      "\n",
      "Ziebart, Brian  - machine learning reading group|Intro. to Number Theory\n",
      "\n",
      "William E. Walden  - Topics in Ecology and Evolutionary Biology|Back to the Future: Nostalgia & Futurity in Contemporary Sci-Fi TV & Telefantasy\n",
      "\n",
      "Amy Bailey  - Introduction to Science and Society: Theories and Controversies\n",
      "\n",
      "Julia Fish  - 3D Photography & Geometry Processing|The Foundation of Living Systems|Intro. to Computation for the Humanities and Social Sciences|Intro. to Computer Graphicz\n",
      "\n",
      "Clarno, Andy  - Chemical Process Design|Intro. to Computation for the Humanities & Social Sciences\n",
      "\n",
      "Erik Jones  - Partial Differential Equationz|Building Intelligent Robots|The Literary Scholar\n",
      "\n",
      "Milan Velebit  - Transport and Biotransport Processes|Reinventionz of Life: Aesthetics, Biopolitics, and the Avant-Gardes|Autonomous Agents and Computational Market Design|Advanced Programming for Digital Art and Literature\n",
      "\n",
      "Bailey  - operating systems\n",
      "\n",
      "Yanky Lekili  - Introductory Calculus, Part I|Filtering & Prediction of Hidden Markov Models\n",
      "\n",
      "Bassiri, Hormoz  - Principles of Ecology\n",
      "\n",
      "Tanya.Bergerwolf  - writing & speaking chinese i|Biomaterialz|Advanced Probabilistic Methods in Computer Science|Introduction to Filmmaking: Time & Form|Topics in Information Retrieval and Web Search|Architecture of the House Through Space and Time\n",
      "\n",
      "Eriksson, Jakob  - intro to computation for the humanities and social sciences|Computer Graphics Lab\n",
      "\n",
      "Anjum Ansari  - Foundationz of Electromagnetism and Modern Physics|Structural Analysis|American Fiction and Mass Culture\n",
      "\n",
      "Steve Sauerwald  - The Postcolonial and the Postmodern|Topics in Information Retrieval & Web Search|Computer Vision|Talking with Computers\n",
      "\n",
      "Sara D. Dunn  - introduction to architectural design\n",
      "\n",
      "William Walden  - special topicz in advanced algorithms|Environmental History|Introduction to Systems Programming|Topics in 3D Game Engine Development|Human Factors and User Interface Design\n",
      "\n",
      "Paolo Vinella  - topics in computer vision|Software System Design|Intro to Combinatorial Optimization\n",
      "\n",
      "Tanya Bergerwolf  - building a web application|Computational Methodz for Biology\n",
      "\n",
      "Mimi Dai  - introductory calculus, part ii\n",
      "\n",
      "Krall, Aaron  - nature and law in american literature\n",
      "\n",
      "Leon Fink  - the korean war in color|The Public Intellectual\n",
      "\n",
      "John Lillis  - Coding the Matrix: Linear Algebra through Computer Science Applicationz|Parallel and Distributed Programming|Intro to Computation for the Humanities & Social Sciences|Educational Software Seminar|Advanced Programming for Digital Art and Literature\n",
      "\n",
      "Will Walden  - Hilbert Spaces & Their Applications|Interdisciplinary Scientific Visualization\n",
      "\n",
      "Sistla, Prasad  - Intro. to Power Engineering|Database Management Systems|Dynamics & Vibrations\n",
      "\n",
      "Savar, Nina  - fieldwork in the urban community|Computational Topology|Intellectual Life & Culture in the Post-Western World\n",
      "\n",
      "Robert Kenyon  - Human Factors & User Interface Design\n",
      "\n",
      "Alexander Chudnovsky  - Fracture Mechanics|Intro. to Computation for the Humanities & Social Sciences|Foundations of Electromagnetism and Modern Physics|Topics in Grounded Language for Robotics\n",
      "\n",
      "Chris Kanich  - Computer Networks|Nineteenth-Century British Novel|Accelerated Introduction to Computer Science\n",
      "\n",
      "Mitch Theys  - Principles of Ecology|Introduction to Algorithms & Data Structures\n",
      "\n",
      "Lyons, Leilah  - cultures and countercultures: the american novel after world war ii|Human-Computer Interaction Seminar\n",
      "\n",
      "Troy, A. Patrick  - Computer Aided Visualization and Design\n",
      "\n",
      "Boy, Ugo  - hilbert spaces and their applications|Introduction to Filmmaking: Time and Form|Narrative and Immersion\n",
      "\n",
      "Cynthia Taylor  - biophysical & bioinorganic chemistry|The Aesthetics of Color: History, Theory, Critique\n",
      "\n",
      "Balajee Vamanan  - Data-Driven Vizion and Graphics|Complex Function Theory|Dynamics and Vibrations\n",
      "\n",
      "Aaron Krall  - nineteenth-century britizh novel|The Postcolonial and the Postmodern\n",
      "\n",
      "Joseph Hummel  - Transport and Biotransport Processes|Introduction to Algorithms and Data Structures|Introductory Calculuz, Part II|Introductory Compiler Construction\n",
      "\n",
      "Douglas Hogan  - operations research: probabilistic models|Computational Theory of Molecular Evolution|Interdisciplinary Scientific Visualization\n",
      "\n",
      "Didem Ozevin  - transport & biotransport processes|Honors Linear Algebra|Intro. to Scientific Computing & Problem Solving|Fundamentals of Computer Systems\n",
      "\n",
      "Robert Sloan  - introduction to computational linguistics\n",
      "\n",
      "Cody Cranch  - 3D Photography & Geometry Processing\n",
      "\n",
      "Gillet, Henri  - analytic geometry and calculus\n",
      "\n",
      "Lenore Zuck  - statistical inference ii|Basic Physics\n",
      "\n",
      "Jon Solworth  - Mechanics of Solids|Nineteenth-Century Architecture|Intro. to Computation for the Humanities and Social Sciences\n",
      "\n",
      "Eric Jones  - Filtering and Prediction of Hidden Markov Models\n",
      "\n",
      "Elisabeta Marai  - 2d game engines|Temporalitiez\n",
      "\n",
      "Ali O. Tafti  - Recent Applications of Probability & Statistics|Introduction to Scientific Computing\n",
      "\n",
      "Di Eugenio, Barbara  - the united states metropolis|Computational Physics|Fracture Mechanics\n",
      "\n",
      "Reed, Dale  - Thermodynamics|Introduction to Discrete Structures & Probability\n",
      "\n",
      "Vahe Caliskan  - electrical circuits & signals|Analytic Geometry & Calculus|Melville, Conrad, & the Sea|Statistical Mechanics\n",
      "\n",
      "Shonfeld, Dan  - Heat & Mass Transfer|Computer Aided Visualization & Design|Medical Bioinformatics\n",
      "\n",
      "Matthew D Siber  - Cell & Molecular Biology\n",
      "\n",
      "Philip Yu  - Special Topics in Advanced Algorithms\n",
      "\n",
      "Forbes, Angus  - Introductory Biochemistry\n",
      "\n",
      "Stephen Checkoway  - getting emotional: passionate theories|Topics in Ecology and Evolutionary Biology|Computer Systems Security: Principles & Practice|Intro to Combinatorial Optimization\n",
      "\n",
      "Sinapova, Dima  - Intro to Computational Geometry|The Claims of Fiction\n",
      "\n",
      "Henri Y. Gillet  - pompeii: art, architecture, & archaeology in the lost city|Quantum Mechanics\n",
      "\n",
      "Tafti, Ali  - topics in game-theoretic artificial intelligence|Advanced Programming for Digital Art & Literature\n",
      "\n",
      "Troy, Patrick  - the design and analysis of trading agents|Introductory Compiler Construction\n",
      "\n",
      "Aireza Mojab  - Intro. to Power Engineering|Individual Independent Study\n",
      "\n",
      "Furman, Alex  - probabilistic methods in computer science|Art After India\n",
      "\n",
      "Leilah Lyons  - writing & speaking german i|Intro. to Sceintific Computing|Reinventions of Life: Aesthetics, Biopolitics, and the Avant-Gardes|Internet and Web Algorithms\n",
      "\n",
      "piotr.gmytrasiewicz  - topics in ecology & evolutionary biology|Literary Communities|Computational Methodz for Biology|Fundamentals of Computer Systems\n",
      "\n",
      "Steven Sauerwald  - American Poetry II: Modernism|Pattern Recognition & Machine Learning|Computer Systems Security: Principles and Practice|Writing and Speaking Chinese I\n",
      "\n",
      "Mitchell Theys  - virtual citizens or subjects? the global battle over governing your internet|Cinematic Coding and Narrativity|Inventing the Past: Amulets, Heirlooms, Monuments, Landscapes\n",
      "\n",
      "Hormoz Bassiri  - Heat and Mass Transfer\n",
      "\n",
      "Philip S Yu  - altered states|Applied Artifical Intelligence\n",
      "\n",
      "Lu, Hui  - crossing the consumer chasm by design|Temporalities\n",
      "\n",
      "Bhaskar DasGupta  - cultures & countercultures: the american novel after world war ii\n",
      "\n",
      "Ning Jin  - Hilbert Spaces & Their Applications|Advanced Algorithms Seminar\n",
      "\n",
      "Wenjing Rao  - collections & visual knowledge in early modern europe|Independent Study in 2D Game Engines|Combinatorial Topology|Touring the Empire: Travel Literature and the Idea of America\n",
      "\n",
      "Metlushko, Vitali  - women's voices in medieval literature|Stem Cell Engineering|Mathematical Statistics|Melville, Conrad, and the Sea\n",
      "\n",
      "Mitch Theys  - Foundationz of Electromagnetism and Modern Physics|Distributed Computing through Combinatorial Topology\n",
      "\n",
      "Westland, Chris  - Probabilistic Graphical Models|Victorian Inequality|Melville, Conrad, & the Sea|Narrative and Immersion|Projects in Engineering Design|Introductory Calculuz, Part II\n",
      "\n",
      "A. Prasad Sistla  - pompeii: art, architecture, and archaeology in the lost city|Molecular Genetics|Intro. to Computer Graphics|El Greco and Velazquez|Algorithmic Foundations of Computational Biology\n",
      "\n",
      "Soheili, Negar  - shakespeare|Biophysical and Bioinorganic Chemistry\n",
      "\n",
      "Yu, Philip  - Computers and Human Values\n",
      "\n",
      "Krishna Reddy  - Reinventions of Life: Aesthetics, Biopolitics, and the Avant-Gardes|Altered Statez|Quantum Mechanics\n",
      "\n",
      "Ana Cui  - the postcolonial & the postmodern|Computational Theory of Molecular Evolution\n",
      "\n",
      "Ajay Kshemkalyani  - Introductory Calculus, Part I\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('class.txt') as csvfile:\n",
    "    for row in csvfile:\n",
    "          print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I - Split the rows into logical strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:\n",
    "First we have to split the name of the professor from the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kshemkalyani, Ajay parallel computation: models, algorithms, limits|Filtering and Prediction of Hidden Markov Models\n"
     ]
    }
   ],
   "source": [
    "def separate_name_from_classes(row):\n",
    "    return row.split(\"  - \")\n",
    "\n",
    "row = \"Kshemkalyani, Ajay  - parallel computation: models, algorithms, limits|Filtering and Prediction of Hidden Markov Models\"\n",
    "name, classes = separate_name_from_classes(row)\n",
    "print(name, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "Then we have to separate the classes into a list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Biology', 'Science of Mind']\n"
     ]
    }
   ],
   "source": [
    "def separate_classes(classes):\n",
    "    return re.split(\"\\|\", classes)\n",
    "\n",
    "classes_list = separate_classes(classes)\n",
    "print(classes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "Now we have the logic to split each row into logical strings that we can later clean up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II - Handling Different Name Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this CSV, names seem to be in the following formats:\n",
    "    1. John Doe\n",
    "    2. John H. Doe\n",
    "    3. John H Doe\n",
    "    4. Doe, John\n",
    "    5. Doe, H. John\n",
    "    6. Doe, H John\n",
    "    7. Doe\n",
    "    8. john.doe\n",
    "    \n",
    "In this case it would be very simple to create regular expressions to handle the various name formats into one single format. I'll use the following universal format for testing:\n",
    " - John Doe (ignoring middle initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:\n",
    "Create regular expressions and get the last name only (only last name required for this assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_formats = ['John Doe', 'John H. Doe', 'John H Doe', 'Doe, John', 'Doe, H. John', 'Doe, H John']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe\n"
     ]
    }
   ],
   "source": [
    "# John Doe\n",
    "reg1 = re.match(r\"(?P<first_name>\\w+) (?P<last_name>\\w+)\", name_formats[0])\n",
    "print(\"{0} {1}\".format(reg1.group('first_name'), reg1.group('last_name'))) # success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe\n",
      "John Doe\n"
     ]
    }
   ],
   "source": [
    "# John H. Doe and John H Doe\n",
    "pattern = re.compile(r\"(?P<first_name>\\w+) (?P<middle_initial>)(\\w+.|\\w+) (?P<last_name>\\w+)\")\n",
    "reg2 = re.match(pattern, name_formats[1])\n",
    "reg3 = re.match(pattern, name_formats[2])\n",
    "print(\"{0} {1}\".format(reg2.group('first_name'), reg2.group('last_name'))) # success!\n",
    "print(\"{0} {1}\".format(reg3.group('first_name'), reg3.group('last_name'))) # success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe\n"
     ]
    }
   ],
   "source": [
    "# Doe, John\n",
    "reg4 = re.match(r\"(?P<last_name>\\w+), (?P<first_name>\\w+)\", name_formats[3])\n",
    "print(\"{0} {1}\".format(reg4.group('first_name'), reg4.group('last_name'))) # success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe\n",
      "John Doe\n"
     ]
    }
   ],
   "source": [
    "# Doe, H. John and Doe, H John\n",
    "pattern = re.compile(r\"(?P<last_name>\\w+), (?P<middle_initial>)(\\w+.|\\w+) (?P<first_name>\\w+)\")\n",
    "reg5 = re.match(pattern, name_formats[4])\n",
    "reg6 = re.match(pattern, name_formats[5])\n",
    "print(\"{0} {1}\".format(reg5.group('first_name'), reg5.group('last_name'))) # success!\n",
    "print(\"{0} {1}\".format(reg6.group('first_name'), reg6.group('last_name'))) # success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "Now combine the multiple regular expressions into 2 regular expressions with the following format:\n",
    " - John Doe\n",
    " - Doe, John\n",
    " \n",
    " For example, any name with the format \"first m.i. last\" should be parsed using one regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doe\n",
      "Doe\n",
      "Doe\n"
     ]
    }
   ],
   "source": [
    "# <firstname> <m.i.>(optional) <lastname>\n",
    "pattern = re.compile(r\"(?P<first_name>\\w+)( (?P<middle_initial>)(\\w+.|\\w+) | )(?P<last_name>\\w+)\")\n",
    "reg1 = re.match(pattern, name_formats[0])\n",
    "reg2 = re.match(pattern, name_formats[1])\n",
    "reg3 = re.match(pattern, name_formats[2])\n",
    "print(reg1.group('last_name'))\n",
    "print(reg2.group('last_name'))\n",
    "print(reg3.group('last_name')) # success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doe\n",
      "Doe\n",
      "Doe\n"
     ]
    }
   ],
   "source": [
    "# <lastname>, <m.i>(optional) or <m.i>.(optional) <firstname>\n",
    "pattern = re.compile(r\"(?P<last_name>\\w+),( (?P<middle_initial>)(\\w+.|\\w+) | )(?P<first_name>\\w+)\")\n",
    "reg4 = re.match(pattern, name_formats[3])\n",
    "reg5 = re.match(pattern, name_formats[4])\n",
    "reg6 = re.match(pattern, name_formats[5])\n",
    "print(reg4.group('last_name'))\n",
    "print(reg5.group('last_name'))\n",
    "print(reg6.group('last_name')) # success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3:\n",
    "Let's combile the two into one easy to use function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_name': 'Doe', 'first_name': 'John'}\n",
      "{'last_name': 'Doe', 'middle_initial': 'H', 'first_name': 'John'}\n",
      "{'last_name': 'Doe', 'middle_initial': 'H', 'first_name': 'John'}\n",
      "{'last_name': 'Doe', 'first_name': 'John'}\n",
      "{'last_name': 'Doe', 'middle_initial': 'H', 'first_name': 'John'}\n",
      "{'last_name': 'Doe', 'middle_initial': 'H', 'first_name': 'John'}\n",
      "{'last_name': 'Doe'}\n",
      "{'last_name': 'Doe'}\n",
      "{'last_name': 'Doe', 'middle_initial': 'Homer', 'first_name': 'J'}\n",
      "{'first_name': 'John', 'last_name': 'Doe'}\n"
     ]
    }
   ],
   "source": [
    "def remove_punctuation(word):\n",
    "    remove_punc_pattern = r'\\w*'\n",
    "    return re.match(remove_punc_pattern, word).group(0)\n",
    "\n",
    "def get_name(unknown_name_format):\n",
    "    \n",
    "    name_dict = {}\n",
    "    pattern = None\n",
    "    \n",
    "    # format is firstname.lastname\n",
    "    if len(unknown_name_format.split('.')) == 2 and len(unknown_name_format.split(' ')) == 1:\n",
    "        first_name, last_name = unknown_name_format.split('.')\n",
    "        return {'last_name':last_name.capitalize(), 'first_name':first_name.capitalize()}\n",
    "        \n",
    "    # one word in name\n",
    "    elif len(unknown_name_format.split(' ')) == 1:\n",
    "        return {'last_name':remove_punctuation(unknown_name_format).capitalize()}\n",
    "    \n",
    "    # if comma after first word\n",
    "    elif unknown_name_format.split(\" \")[0][-1] == ',':\n",
    "        pattern = re.compile(r\"(?P<last_name>\\w+,)\\s(((?P<middle_initial>\\w+.|\\w+)\\s)|\\b)((?P<first_name>\\w+))|\\b\")\n",
    "        \n",
    "    else:\n",
    "        pattern = re.compile(r\"(?P<first_name>\\w+(.|\\b))\\s*(((?P<middle_initial>\\w+|\\w+.)\\s)|\\b)(?P<last_name>\\w*)\")\n",
    "    \n",
    "    reg = re.match(pattern, unknown_name_format)\n",
    "\n",
    "    if reg.group('first_name'):\n",
    "        name_dict['first_name'] = remove_puncuation(reg.group('first_name')).capitalize()\n",
    "\n",
    "    if reg.group('middle_initial'):\n",
    "        name_dict['middle_initial'] = remove_punctuation(reg.group('middle_initial')).capitalize()\n",
    "\n",
    "    if reg.group('last_name'):\n",
    "        name_dict['last_name'] = remove_punctuation(reg.group('last_name')).capitalize()\n",
    "    \n",
    "    return name_dict;\n",
    "\n",
    "print(get_name(\"John Doe\"))\n",
    "print(get_name(\"John H. Doe\"))\n",
    "print(get_name(\"John H Doe\"))\n",
    "print(get_name(\"Doe, John\"))\n",
    "print(get_name(\"Doe, H John\"))\n",
    "print(get_name(\"Doe, H. John\"))\n",
    "print(get_name(\"Doe\"))\n",
    "print(get_name(\"Doe,\"))\n",
    "print(get_name(\"J. Homer Doe\"))\n",
    "print(get_name(\"john.doe\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Now we have the proper regular expressions to handle the various name formats that exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III - Clean up the classes\n",
    "Now that we've cleaned up the names, let's clean up the classes. By looking at the classes you'll notice that there are the following issues:\n",
    "    1. Incorrect spelling in some cases\n",
    "    2. Incorrect caps\n",
    "    3. More? (look at the data more closely for more possible issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:\n",
    "Let's begin with ensuring each sentence has proper spelling. This is especially difficult because we have to account for special cases such as roman numerals and abbreviations (i.e. intro).\n",
    "\n",
    "For the first step of spelling, I will use the python library \"enchant\" to discover when a word is mispelled. Take note that it looks like the person who wrote this document made single character mistakes. We can fix that with echant using sudo logic that looks like this:\n",
    "\n",
    "  ```\n",
    "  if a word is mispelled\n",
    "    suggest new words\n",
    "    iterate through the suggested words\n",
    "    if the new suggested word is the same length but has once character off\n",
    "      take that suggestion\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel computation: models, algorithms, limits\n",
      "Filtering and Prediction of Hidden Markov Models\n",
      "computer vision part ii\n",
      "Descartes' World\n",
      "American Fiction & Mass Culture\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Bio materials',\n",
       " 'Bio-materials',\n",
       " 'Materials',\n",
       " \"Material's\",\n",
       " 'Immaterial',\n",
       " 'Material',\n",
       " \"Materiel's\",\n",
       " 'Bilateral',\n",
       " 'Imperials',\n",
       " 'Immaterially',\n",
       " \"Imperial's\"]"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import enchant\n",
    "\n",
    "def correct_sentence_spelling(sentence):\n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    corrected_sentence = []\n",
    "    \n",
    "    for word_with_special_chars in sentence.split(\" \"):\n",
    "        word = ''\n",
    "        reg = None\n",
    "        \n",
    "        # replace any '&' with 'and'\n",
    "        if word_with_special_chars == '&':\n",
    "            word = 'and'\n",
    "            \n",
    "        reg = re.match(r\"(?P<pre>[.,!?;:']*)(?P<word>[\\w&]*)(?P<post>[.,!?;:']*)\", word_with_special_chars) # group words and punctuation\n",
    "        alpha_numeric_word = reg.group('word')\n",
    "        \n",
    "        #save punctuation before and after the word\n",
    "        pre = reg.group('pre')\n",
    "        post = reg.group('post')\n",
    "        \n",
    "        if d.check(alpha_numeric_word) == False: # word isn't spelled correctly\n",
    "\n",
    "            # find first closest suggested word\n",
    "            for suggested_word in d.suggest(alpha_numeric_word):\n",
    "                if len(alpha_numeric_word) == len(suggested_word):\n",
    "                    word = suggested_word\n",
    "                    break\n",
    "        else:\n",
    "            word = alpha_numeric_word\n",
    "        \n",
    "        word = word_with_special_chars.replace(word_with_special_chars, word)\n",
    "        corrected_sentence.append(pre+word+post)\n",
    "    return \" \".join(corrected_sentence)\n",
    "\n",
    "example_class_list = ['parallel computation: modelz, algorithms, limitz',\n",
    "                      'Filtering and Prediction of Hidden Markov Modelz', 'computer vizion part ii', \n",
    "                      \"Descartes' World\", 'American Fiction & Mass Culture\\n', 'Biomaterials']\n",
    "\n",
    "for sentence in example_class_list:\n",
    "    print(correct_sentence_spelling(sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "Now that we've ensured the spelling is correct for the most part, we need to find a way to capitalize each word appropriately. We should take the following rules into account:\n",
    "    - First word of a sentence is capitalized\n",
    "    - Last word of a sentence is capitalized\n",
    "    - The following words will not be capitalized: a, an, the, at, by, for, in, of, on, to, up, and, as, but, or. \n",
    "\n",
    "[Word Source](http://grammar.yourdictionary.com/capitalization/rules-for-capitalization-in-titles.html#QKr4elbmMtimKfJz.99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pompeii's Fall 101: Art, Architecture, & Archaeology in the Lost City\n",
      "Descartes' World World\n",
      "Biomaterials\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def fix_sentence_case(sentence):\n",
    "    \n",
    "    lower_case_words = ['a', 'an', 'the', 'at', 'by', 'for', 'in', 'of', 'on', 'to', 'up', 'and', 'as', 'but', 'or']\n",
    "    \n",
    "    old_sentence_list = sentence.split(\" \")\n",
    "    \n",
    "    first_word = old_sentence_list[0].capitalize()\n",
    "    \n",
    "    if len(old_sentence_list) == 1:\n",
    "        return first_word\n",
    "    \n",
    "    last_word = old_sentence_list[-1].capitalize()\n",
    "    \n",
    "    new_sentence = []\n",
    "    new_sentence.append(first_word)\n",
    "    \n",
    "    old_sentence_list.pop(0) # remove first word, it's been capitalized and saved\n",
    "    \n",
    "    if len(old_sentence_list) > 1:\n",
    "        old_sentence_list.pop(len(old_sentence_list)-1) # remove the last word, it's been capitalized and saved\n",
    "\n",
    "    for word in old_sentence_list:\n",
    "            \n",
    "        reg_ex = re.match(r\"(\\w+)\", word) # strip special characters i.e. ':' or ','\n",
    "        \n",
    "        # test that the word is alpha numeric\n",
    "        if reg_ex is not None and reg_ex.group(0) not in lower_case_words:\n",
    "            alpha_numeric_word = reg_ex.group(0)\n",
    "            capitalized_word = alpha_numeric_word.capitalize()\n",
    "            word = word.replace(alpha_numeric_word, capitalized_word) # maintain special chars i.e. 'Test:' or 'yes,'\n",
    "            new_sentence.append(word)\n",
    "            \n",
    "        else:\n",
    "            new_sentence.append(word)\n",
    "\n",
    "    new_sentence.append(last_word)\n",
    "    return \" \".join(new_sentence)\n",
    "\n",
    "sentences = ['pompeii\\'s fall 101: art, architecture, & archaeology in the lost city', 'Descartes\\' World', 'Biomaterials']\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(fix_sentence_case(sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV - Combining the Pieces\n",
    "Now that we've built a series of functions that are workable with our given text file, we can now combine them to create a \"clean copy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:\n",
    "Take a list of classes and append them with a \"|\" as in the original text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a sentence|this is also a sentence|this is another sentence\n"
     ]
    }
   ],
   "source": [
    "def join_sentences_with_pipe(sentences):\n",
    "    return '|'.join(sentences)\n",
    "\n",
    "sentences = ['this is a sentence', 'this is also a sentence', 'this is another sentence']\n",
    "print(join_sentences_with_pipe(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "Now that we've merges the classes, we can now combine the classes with the professor name. In this example, I will use the last name of the professor because it's conveniately unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doe  - Biology|Science of Mind\n"
     ]
    }
   ],
   "source": [
    "def join_name_with_classes(name, classes):\n",
    "    return name + '  - ' + classes\n",
    "\n",
    "classes = 'Biology|Science of Mind'\n",
    "name = 'Doe'\n",
    "print(join_name_with_classes(name, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:\n",
    "Now that we've cleaned the data, let's combine the data into a dictionary where the professor name is the key and the courses he/she teaches is the value.\n",
    "\n",
    "Note: In this case, we must assume that there are duplicate rows in the CSV. A dictionary will handle this case well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Doe': ['The science of mind', \"Let's Embrace Fear\"]}\n",
      "{'Doe': ['The science of mind', \"Let's Embrace Fear\", 'Living life fully']}\n",
      "{'Smith': [\"It's just the way it is\"], 'Doe': ['The science of mind', \"Let's Embrace Fear\", 'Living life fully']}\n"
     ]
    }
   ],
   "source": [
    "def build_dictionary(dictionary, name, classes):\n",
    "    try:\n",
    "        for a_class in classes:\n",
    "            dictionary[name].append(a_class)\n",
    "    except KeyError:\n",
    "        dictionary[name] = classes\n",
    "    return dictionary\n",
    "\n",
    "temp_dict = {}\n",
    "name = 'Doe'\n",
    "classes = ['The science of mind', 'Let\\'s Embrace Fear']\n",
    "\n",
    "print(build_dictionary(temp_dict, name, classes))\n",
    "\n",
    "name = 'Doe'\n",
    "classes = ['Living life fully']\n",
    "\n",
    "print(build_dictionary(temp_dict, name, classes))\n",
    "\n",
    "name = 'Smith'\n",
    "classes = ['It\\'s just the way it is']\n",
    "\n",
    "print(build_dictionary(temp_dict, name, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "For the final step, let's combine the functions we created throughout this tutorial to generate a document that is properly capitalized, and spelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Siber': ['Reading & Research', '3d Photography\\n Photography\\n', 'Cell & Molecular Biology\\n'], 'Vinella': ['Topics in Computer Vision', 'Software System Design', 'Intro to Combinatorial Optimization\\n'], 'Kanich': ['Computer Networks Networks', 'Nineteenth-century British Novel', 'Accelerated Introduction to Computer Science\\n'], 'Walden': ['Topics in Ecology and Evolutionary Biology', 'Back to the Future: Nostalgia & Futurity in Contemporary Sci-Fi Tv & Telefantasy\\n', 'Special Topicz in Advanced Algorithms', 'Environmental History History', 'Introduction to Systems Programming', 'Topics in 3d Game Engine Development', 'Human Factors and User Interface Design\\n', 'Hilbert Spaces & Their Applications', 'Interdisciplinary Scientific Visualization\\n'], 'Sloan': ['Introduction to Computational Linguistics\\n'], 'Yu': ['Special Topics in Advanced Algorithms\\n', 'Altered States States', 'Applied Artifical Intelligence\\n', 'Computers and Human Values\\n'], 'Marai': ['2d Game Engines', 'Temporalitiez\\n'], 'Mojab': ['Intro. to Power Engineering', 'Individual Independent Study\\n'], 'Vamanan': ['Data-driven Vizion and Graphics', 'Complex Function Theory', 'Dynamics and Vibrations\\n'], 'Sinapova': ['Intro to Computational Geometry', 'The Claims of Fiction\\n'], 'Ozevin': ['Transport & Biotransport Processes', 'Honors Linear Algebra', 'Intro. to Scientific Computing & Problem Solving', 'Fundamentals of Computer Systems\\n'], 'Boy': ['Hilbert Spaces and Their Applications', 'Introduction to Filmmaking: Time and Form', 'Narrative and Immersion\\n'], 'Ansari': ['Foundationz of Electromagnetism and Modern Physics', 'Structural Analysis Analysis', 'American Fiction and Mass Culture\\n'], 'Bassiri': ['Principles of Ecology\\n', 'Heat and Mass Transfer\\n'], 'Lillis': ['Coding the Matrix: Linear Algebra Through Computer Science Applicationz', 'Parallel and Distributed Programming', 'Intro to Computation for the Humanities & Social Sciences', 'Educational Software Seminar', 'Advanced Programming for Digital Art and Literature\\n'], 'Reed': ['Thermodynamics', 'Introduction to Discrete Structures & Probability\\n'], 'Shonfeld': ['Heat & Mass Transfer', 'Computer Aided Visualization & Design', 'Medical Bioinformatics\\n Bioinformatics\\n'], 'Lekili': ['Introductory Calculus, Part I', 'Filtering & Prediction of Hidden Markov Models\\n'], 'Jones': ['Partial Differential Equationz', 'Building Intelligent Robots', 'The Literary Scholar\\n', 'Filtering and Prediction of Hidden Markov Models\\n'], 'Theys': ['Principles of Ecology', 'Introduction to Algorithms & Data Structures\\n', 'Virtual Citizens or Subjects? the Global Battle Over Governing Your Internet', 'Cinematic Coding and Narrativity', 'Inventing the Past: Amulets, Heirlooms, Monuments, Landscapes\\n', 'Foundationz of Electromagnetism and Modern Physics', 'Distributed Computing Through Combinatorial Topology\\n'], 'Forbes': ['Introductory Biochemistry\\n Biochemistry\\n'], 'Gmytrasiewicz': ['Topics in Ecology & Evolutionary Biology', 'Literary Communities Communities', 'Computational Methodz for Biology', 'Fundamentals of Computer Systems\\n'], 'Dunn': ['Introduction to Architectural Design\\n'], 'Brennan': ['Intermediate 3d Computer Animation', 'Astrophysics and Cosmology\\n'], 'Hogan': ['Operations Research: Probabilistic Models', 'Computational Theory of Molecular Evolution', 'Interdisciplinary Scientific Visualization\\n'], 'Dai': ['Introductory Calculus, Part Ii\\n'], 'Fink': ['The Korean War in Color', 'The Public Intellectual\\n'], 'Rao': ['Collections & Visual Knowledge in Early Modern Europe', 'Independent Study in 2d Game Engines', 'Combinatorial Topology Topology', 'Touring the Empire: Travel Literature and the Idea of America\\n'], 'Bell': ['Software Engineering Engineering', 'Photo-lab: The Visual Performance of Rights', 'Art After India\\n'], 'Zuck': ['Statistical Inference Ii', 'Basic Physics\\n Physics\\n'], 'Johnson': ['Cell & Molecular Biology', 'Computer Aided Visualization and Design\\n'], 'Bergerwolf': ['Recent Applications of Probability & Statistics', 'Algorithms for Big Data\\n', 'Writing & Speaking Chinese I', 'Biomaterialz', 'Advanced Probabilistic Methods in Computer Science', 'Introduction to Filmmaking: Time & Form', 'Topics in Information Retrieval and Web Search', 'Architecture of the House Through Space and Time\\n', 'Building a Web Application', 'Computational Methodz for Biology\\n'], 'Lyons': ['Cultures and Countercultures: the American Novel After World War Ii', 'Human-computer Interaction Seminar\\n', 'Writing & Speaking German I', 'Intro. to Sceintific Computing', 'Reinventions of Life: Aesthetics, Biopolitics, and the Avant-gardes', 'Internet and Web Algorithms\\n'], 'Cui': ['The Postcolonial & the Postmodern', 'Computational Theory of Molecular Evolution\\n'], 'Metlushko': [\"Women's Voices in Medieval Literature\", 'Stem Cell Engineering', 'Mathematical Statistics Statistics', 'Melville, Conrad, and the Sea\\n'], 'Velebit': ['Transport and Biotransport Processes', 'Reinventionz of Life: Aesthetics, Biopolitics, and the Avant-gardes', 'Autonomous Agents and Computational Market Design', 'Advanced Programming for Digital Art and Literature\\n'], 'Reddy': ['Reinventions of Life: Aesthetics, Biopolitics, and the Avant-gardes', 'Altered Statez Statez', 'Quantum Mechanics\\n Mechanics\\n'], 'Wolak': [\"Descartes' World World\", 'American Fiction & Mass Culture\\n'], 'Archias': ['Collections and Visual Knowledge in Early Modern Europe', 'Intro. to Modernism: Past, Future, Exile, Home\\n'], 'Taylor': ['Biophysical & Bioinorganic Chemistry', 'The Aesthetics of Color: History, Theory, Critique\\n'], 'Solworth': ['Mechanics of Solids', 'Nineteenth-century Architecture Architecture', 'Intro. to Computation for the Humanities and Social Sciences\\n'], 'Eriksson': ['Intro to Computation for the Humanities and Social Sciences', 'Computer Graphics Lab\\n'], 'Soheili': ['Shakespeare', 'Biophysical and Bioinorganic Chemistry\\n'], 'Hummel': ['Transport and Biotransport Processes', 'Introduction to Algorithms and Data Structures', 'Introductory Calculuz, Part Ii', 'Introductory Compiler Construction\\n'], 'Gillet': ['Data-driven Vision and Graphics', 'Algebraic Geometry\\n Geometry\\n', 'Analytic Geometry and Calculus\\n', 'Pompeii: Art, Architecture, & Archaeology in the Lost City', 'Quantum Mechanics\\n Mechanics\\n'], 'Ziebart': ['Machine Learning Reading Group', 'Intro. to Number Theory\\n'], 'Foster': ['Mechanics of Solids', 'Analytic Geometry & Calculus\\n'], 'Kshemkalyani': ['Parallel Computation: Models, Algorithms, Limits', 'Filtering and Prediction of Hidden Markov Models\\n', 'Introductory Calculus, Part I\\n'], 'Furman': ['Probabilistic Graphical Models', 'Distributed Computing Through Combinatorial Topology\\n', 'Probabilistic Methods in Computer Science', 'Art After India\\n'], 'Jin': ['Hilbert Spaces & Their Applications', 'Advanced Algorithms Seminar\\n'], 'Krall': ['Nature and Law in American Literature\\n', 'Nineteenth-century Britizh Novel', 'The Postcolonial and the Postmodern\\n'], 'Dasgupta': ['Parallel Computation: Modelz, Algorithms, Limits\\n', 'Cultures & Countercultures: the American Novel After World War Ii\\n'], 'Tafti': ['Managerial Decision Making', 'The Design & Analysis of Trading Agents', 'Topics in Data Science\\n', 'Recent Applications of Probability & Statistics', 'Introduction to Scientific Computing\\n', 'Topics in Game-theoretic Artificial Intelligence', 'Advanced Programming for Digital Art & Literature\\n'], 'Adiutori': ['American Fiction & Mass Culture\\n'], 'Westland': ['Probabilistic Graphical Models', 'Victorian Inequality Inequality', 'Melville, Conrad, & the Sea', 'Narrative and Immersion', 'Projects in Engineering Design', 'Introductory Calculuz, Part Ii\\n'], 'Gallik': ['Molecular Genetics Genetics', 'Intro. to Computer Graphicz\\n'], 'Chudnovsky': ['Fracture Mechanics Mechanics', 'Intro. to Computation for the Humanities & Social Sciences', 'Foundations of Electromagnetism and Modern Physics', 'Topics in Grounded Language for Robotics\\n'], 'Troy': ['Computer Aided Visualization and Design\\n', 'The Design and Analysis of Trading Agents', 'Introductory Compiler Construction\\n'], 'Sistla': ['Intro. to Power Engineering', 'Database Management Systems', 'Dynamics & Vibrations\\n', 'Pompeii: Art, Architecture, and Archaeology in the Lost City', 'Molecular Genetics Genetics', 'Intro. to Computer Graphics', 'El Greco and Velazquez', 'Algorithmic Foundations of Computational Biology\\n'], 'Wolfson': ['Data-driven Vizion and Graphics', 'Database Management Systems\\n'], 'Lu': ['Innovation and Technology Management Ii', 'Models of Computation', 'Biomaterials', 'Pattern Recognition and Machine Learning', 'Computational Fluid Dynamics', 'Writing and Speaking Chineze I\\n', 'The Literary Scholar\\n', 'Crossing the Consumer Chasm by Design', 'Temporalities\\n'], 'Sauerwald': ['The Postcolonial and the Postmodern', 'Topics in Information Retrieval & Web Search', 'Computer Vision Vision', 'Talking With Computers\\n', 'American Poetry Ii: Modernism', 'Pattern Recognition & Machine Learning', 'Computer Systems Security: Principles and Practice', 'Writing and Speaking Chinese I\\n'], 'Valbonesi': ['Computer Vizion\\n Vizion\\n'], 'Barbara': ['The United States Metropolis', 'Computational Physics Physics', 'Fracture Mechanics\\n Mechanics\\n'], 'Savar': ['Fieldwork in the Urban Community', 'Computational Topology Topology', 'Intellectual Life & Culture in the Post-Western World\\n'], 'Checkoway': ['Getting Emotional: Passionate Theories', 'Topics in Ecology and Evolutionary Biology', 'Computer Systems Security: Principles & Practice', 'Intro to Combinatorial Optimization\\n'], 'Caliskan': ['Electrical Circuits & Signals', 'Analytic Geometry & Calculus', 'Melville, Conrad, & the Sea', 'Statistical Mechanics\\n Mechanics\\n'], 'Clarno': ['Chemical Process Design', 'Intro. to Computation for the Humanities & Social Sciences\\n'], 'Bailey': ['Introduction to Science and Society: Theories and Controversies\\n', 'Operating Systems\\n Systems\\n'], 'Kenyon': ['Human Factors & User Interface Design\\n'], 'Cranch': ['3d Photography & Geometry Processing\\n'], 'Fish': ['3d Photography & Geometry Processing', 'The Foundation of Living Systems', 'Intro. to Computation for the Humanities and Social Sciences', 'Intro. to Computer Graphicz\\n']}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import enchant\n",
    "import re\n",
    "\n",
    "cleaned_data_dict = {}\n",
    "with open('class.txt') as csvfile:\n",
    "    csv_data_dict = {}\n",
    "    for row_dirty in csvfile:\n",
    "        name_dirty, classes_dirty = separate_name_from_classes(row_dirty)\n",
    "        classes_list_dirty = separate_classes(classes_dirty)\n",
    "        name_clean = get_name(name_dirty)['last_name']\n",
    "        classes_list_clean = []\n",
    "        for a_class_dirty in classes_list_dirty:\n",
    "#             a_class_dirty = correct_sentence_spelling(a_class_dirty) # TODO\n",
    "            a_class_clean = fix_sentence_case(a_class_dirty)\n",
    "            classes_list_clean.append(a_class_clean)\n",
    "        cleaned_data_dict = build_dictionary(cleaned_data_dict, name_clean, classes_list_clean)\n",
    "#         classes_clean = join_sentences_with_pipe(classes_list_clean)\n",
    "#         row_clean = join_name_with_classes(name_clean, classes_clean)\n",
    "#         print(row_clean)\n",
    "print(cleaned_data_dict)\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
