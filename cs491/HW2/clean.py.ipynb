{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import urllib.request\n",
    "import xml.etree.ElementTree as ET\n",
    "import enchant\n",
    "import re\n",
    "import string\n",
    "import re\n",
    "\n",
    "wordnet_dict = {}\n",
    "DictService = False # enabling this significantly slows this program but will result in more accurate spell checking\n",
    "\n",
    "class DataCleaner(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fix_sentence_case(self, sentence):\n",
    "\n",
    "        lower_case_words = ['a', 'an', 'the', 'at', 'by', 'for', 'in', 'of', 'on', 'to', 'up', 'and', 'as', 'but', 'or']\n",
    "\n",
    "        old_sentence_list = sentence.split(\" \")\n",
    "\n",
    "        first_word = old_sentence_list[0].capitalize()\n",
    "\n",
    "        if len(old_sentence_list) == 1:\n",
    "            return first_word\n",
    "\n",
    "        last_word = ''\n",
    "\n",
    "        new_sentence = []\n",
    "        new_sentence.append(first_word)\n",
    "\n",
    "        old_sentence_list.pop(0) # remove first word, it's been capitalized and saved\n",
    "\n",
    "        if len(old_sentence_list) > 1:\n",
    "            last_word = old_sentence_list[-1].capitalize()\n",
    "            old_sentence_list.pop(len(old_sentence_list)-1) # remove the last word, it's been capitalized and saved\n",
    "\n",
    "        for word in old_sentence_list:\n",
    "\n",
    "            reg_ex = re.match(r\"(\\w+)\", word) # strip special characters i.e. ':' or ','\n",
    "\n",
    "            # test that the word is alpha numeric\n",
    "            if reg_ex is not None and reg_ex.group(0) not in lower_case_words:\n",
    "                alpha_numeric_word = reg_ex.group(0)\n",
    "                capitalized_word = alpha_numeric_word.capitalize()\n",
    "                word = word.replace(alpha_numeric_word, capitalized_word) # maintain special chars i.e. 'Test:' or 'yes,'\n",
    "                new_sentence.append(word)\n",
    "\n",
    "            else:\n",
    "                new_sentence.append(word)\n",
    "\n",
    "        new_sentence.append(last_word)\n",
    "        return \" \".join(new_sentence)\n",
    "\n",
    "    def soundex_distance(self, word):\n",
    "        # source: https://en.wikipedia.org/wiki/Soundex\n",
    "\n",
    "        consonants = ['b', 'f', 'p', 'v', 'c', 'g', 'j', 'k', 'q', 's', 'x', 'z', 'd', 't', 'l', 'm', 'n', 'r']\n",
    "\n",
    "        # corresponds to the soudex mapping\n",
    "        mapping = {\n",
    "            'b':1, 'f':1, 'p':1, 'v':1,\n",
    "            'c':2, 'g':2, 'j':2, 'k':2, 'q':2, 's':2, 'x':2, 'z':2,\n",
    "            'd':3, 't':3,\n",
    "            'l':4,\n",
    "            'm':5, 'n':5,\n",
    "            'r':6\n",
    "        }\n",
    "\n",
    "        # Save the first letter. Remove all occurrences of 'h' and 'w' except first letter\n",
    "        first_letter = word[0]\n",
    "        word = word[0] + re.sub(r'[HhWw]', '', word[1:])\n",
    "\n",
    "        # Replace all consonants (include the first letter) with digits as in [2.] above\n",
    "        word = list(word)\n",
    "        for i, letter in enumerate(word):\n",
    "            if letter.lower() in consonants:\n",
    "                word[i] = str(mapping[letter.lower()])\n",
    "\n",
    "        word = ''.join(word)\n",
    "\n",
    "        # Replace all adjacent same digits with one digit.\n",
    "        temp_word = word[0]\n",
    "        i = 1\n",
    "        while i < len(word):  \n",
    "            if word[i] != word[i-1]:\n",
    "                temp_word += word[i]\n",
    "            i+=1\n",
    "\n",
    "        word = temp_word\n",
    "\n",
    "        # Remove all occurrences of a, e, i, o, u, y except first letter.\n",
    "        word = word[0] + re.sub(r'[aeiouyhw]', '', word[1:])\n",
    "\n",
    "        # If first symbol is a digit replace it with letter saved on step 1.\n",
    "        word = re.sub(r'[0-9]', first_letter, word[0]) + word[1:]\n",
    "\n",
    "        # Append 3 zeros if result contains less than 3 digits. Remove all except first letter and 3 digits after it (This step same as [4.] in explanation above).\n",
    "        while len(word) < 4:\n",
    "            word += '0'\n",
    "\n",
    "        return word[:4]\n",
    "\n",
    "    def correct_sentence_spelling(self, sentence):\n",
    "        d = enchant.Dict(\"en_US\")\n",
    "        corrected_sentence = []\n",
    "\n",
    "        for word_with_special_chars in sentence.split(\" \"):\n",
    "            in_wordnet = False\n",
    "            in_dict_service = False\n",
    "            word = ''\n",
    "            reg = None\n",
    "\n",
    "            # replace any '&' with 'and'\n",
    "            if word_with_special_chars == '&':\n",
    "                word = 'and'\n",
    "                continue\n",
    "\n",
    "            reg = re.match(r\"(?P<pre>[.,!?;:']*)(?P<word>[\\w&]*)(?P<post>[.,!?;:']*)\", word_with_special_chars) # group words and punctuation\n",
    "            alpha_numeric_word = reg.group('word')\n",
    "\n",
    "            #save punctuation before and after the word\n",
    "            pre = reg.group('pre')\n",
    "            post = reg.group('post')\n",
    "\n",
    "            # first check word net because it's a constant time lookup\n",
    "            try:\n",
    "                word = wordnet_dict[alpha_numeric_word.lower()]\n",
    "                in_wordnet = True\n",
    "            except KeyError:\n",
    "                word = ''\n",
    "                in_wordnet = False\n",
    "\n",
    "            # now check DictService online dictionary for word\n",
    "            if DictService and dict_service_has_word(alpha_numeric_word):\n",
    "                word = alpha_numeric_word\n",
    "\n",
    "            # now that wornet and dictservice has been checked, lets check enchant\n",
    "            elif in_wordnet == False and d.check(alpha_numeric_word) == False: # word isn't spelled correctly\n",
    "\n",
    "                # find first closest suggested word\n",
    "                for suggested_word in d.suggest(alpha_numeric_word):\n",
    "\n",
    "    #                 print(alpha_numeric_word, suggested_word, d.suggest(alpha_numeric_word))\n",
    "                    word = ''\n",
    "\n",
    "                    # both words have a resonable edit distance and the soundex is the same\n",
    "    #                 if len(alpha_numeric_word) == len(suggested_word) \\\n",
    "    #                 temp_suggested_word = suggested_word.replace(\"-\", \"\").replace(\" \", \"\")\n",
    "                    temp_suggested_word = suggested_word\n",
    "                    if self.edit_distance(alpha_numeric_word.lower(), temp_suggested_word.lower()) < 3 \\\n",
    "                    and self.soundex_distance(alpha_numeric_word.lower()) == self.soundex_distance(temp_suggested_word.lower()):\n",
    "    #                     print(alpha_numeric_word, suggested_word)\n",
    "    #                     test = input(alpha_numeric_word + \" \" + suggested_word)\n",
    "    #                     print(d.suggest(alpha_numeric_word))\n",
    "                        word = suggested_word\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        word = alpha_numeric_word\n",
    "\n",
    "            else:\n",
    "                word = alpha_numeric_word\n",
    "\n",
    "            word = word_with_special_chars.replace(word_with_special_chars, word)\n",
    "            corrected_sentence.append(pre+word+post)\n",
    "    #         print(corrected_sentence)\n",
    "    #         test = input()\n",
    "        return \" \".join(corrected_sentence)\n",
    "\n",
    "    def dict_service_has_word(self, word, strategy='exact'):\n",
    "\n",
    "        url = 'http://services.aonaware.com/DictService/DictService.asmx/Match?word={0}&strategy={1}'.format(word, strategy)\n",
    "    #     print(url)\n",
    "        results = urllib.request.urlopen(url).read()\n",
    "        root = ET.fromstring(results)\n",
    "        for child in root:\n",
    "            for found_word in child:\n",
    "                if found_word.text == word:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def load_wordnet_into_mem(self, filename):\n",
    "        \"\"\"Loads a wordnet csv into a dictionary for later use. The load is only completed once so each lookup can be done\n",
    "        constant time.\"\"\"\n",
    "        temp = {}\n",
    "        with open(filename) as f:\n",
    "            reader = csv.reader(f)\n",
    "            for word in reader:\n",
    "                temp[word[0].lower()] = word[0].lower()\n",
    "        return temp\n",
    "\n",
    "    def resolve_list(self, a_list, mapping):\n",
    "        resolved_list = []\n",
    "        # given a mapping from a->b,\n",
    "        # we want to always map to b\n",
    "        # if the value we're looking for is \n",
    "        # b, than it is already correct\n",
    "        for item in a_list:\n",
    "            # try to find item in mapping and apply that value\n",
    "            try:\n",
    "                resolved_list.append(mapping[item])\n",
    "            # otherwise use the original value i nthe list\n",
    "            except KeyError:\n",
    "                resolved_list.append(item)\n",
    "\n",
    "        return resolved_list\n",
    "\n",
    "    def fold_list_of_lists_to_one_list(self, list_of_lists):\n",
    "        return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "    # loop through each key value pair and see if they are similar\n",
    "    def entity_resolution(self, data, distance_constant=5):\n",
    "        \"\"\"this function maps a word b->a or b->b using a dictionary\"\"\"\n",
    "        resolved_data = {}\n",
    "        for i in range(0, len(data)):\n",
    "            data[i] = data[i].lower()\n",
    "            for j in range(i, len(data)):\n",
    "                if i == j:\n",
    "                    pass\n",
    "                elif self.edit_distance(data[i], data[j]) <= distance_constant:\n",
    "                    try:\n",
    "                        resolved_data[data[j]] = data[i]\n",
    "                    except KeyError:\n",
    "                        resolved_data.append({data[j], data[i]})\n",
    "\n",
    "                # the word is not changes and maps to itself\n",
    "                else:\n",
    "                    try:\n",
    "                        resolved_data[data[j]] = data[j]\n",
    "                    except KeyError:\n",
    "                        resolved_data.append({data[j], data[j]})\n",
    "\n",
    "        return resolved_data;\n",
    "\n",
    "    def edit_distance(self, word1, word2):\n",
    "        \"\"\"This algorithm involves looping through word1 and converting it to word2 letter by letter,\n",
    "        replacing/deleting/inserting each character that doesn't match exactly.\"\"\"\n",
    "\n",
    "        if len(word1) == 0:\n",
    "            return 0\n",
    "        if len(word2) == 0:\n",
    "            return 0\n",
    "\n",
    "        word1 = list(word1.lower())\n",
    "        word2 = list(word2.lower())\n",
    "\n",
    "        distance = 0\n",
    "\n",
    "        # find the shortest word\n",
    "        shortest_word_len = 0\n",
    "        if len(word1) < len(word2):\n",
    "            shortest_word_len = len(word1)\n",
    "        else:\n",
    "            shortest_word_len = len(word2)\n",
    "\n",
    "        # find the longest word\n",
    "        longest_word_len = 0\n",
    "        if len(word1) > len(word2):\n",
    "            longest_word_len = len(word1)\n",
    "        else:\n",
    "            longest_word_len = len(word2)\n",
    "\n",
    "        # loop for the duration of the shortest word\n",
    "        # ensures there is no insertion at this point\n",
    "        # strictly deletion and replacing\n",
    "    #     print(\"\".join(word1), \"\".join(word2))\n",
    "        for i in range(0, shortest_word_len):\n",
    "\n",
    "            # letters are the same\n",
    "            if word1[i] == word2[i]:\n",
    "                pass\n",
    "\n",
    "            # letters are not the same\n",
    "            elif word1[i] != word2[i]:\n",
    "                word1[i] = word2[i]\n",
    "    #             print(\"\".join(word1), \"\".join(word2))\n",
    "                distance += 1\n",
    "\n",
    "        # loop through any remaining characters\n",
    "        # that are empty strings and replace / delete them\n",
    "        for i in range(shortest_word_len, longest_word_len):\n",
    "            # if word2 no longer has letters, than word1 is longer\n",
    "            # deletion is needed\n",
    "            if i >= shortest_word_len and len(word1) > len(word2):\n",
    "                word1.pop()\n",
    "                distance += 1\n",
    "    #             print(\"\".join(word1), \"\".join(word2))\n",
    "                continue\n",
    "\n",
    "            # if letters don't exist in word1 that are in word2\n",
    "            # insertion is needed\n",
    "            try:\n",
    "                word1.append(word2[i])\n",
    "    #             print(\"\".join(word1), \"\".join(word2))\n",
    "                distance += 1\n",
    "                continue\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return distance\n",
    "\n",
    "    def remove_punctuation(self, word):\n",
    "        remove_punc_pattern = r'\\w*'\n",
    "        return re.match(remove_punc_pattern, word).group(0)\n",
    "\n",
    "    def get_name(self, unknown_name_format):\n",
    "\n",
    "        name_dict = {}\n",
    "        pattern = None\n",
    "\n",
    "        # format is firstname.lastname\n",
    "        if len(unknown_name_format.split('.')) == 2 and len(unknown_name_format.split(' ')) == 1:\n",
    "            first_name, last_name = unknown_name_format.split('.')\n",
    "            return {'last_name':last_name.capitalize(), 'first_name':first_name.capitalize()}\n",
    "\n",
    "        # one word in name\n",
    "        elif len(unknown_name_format.split(' ')) == 1:\n",
    "            return {'last_name':self.remove_punctuation(unknown_name_format).capitalize()}\n",
    "\n",
    "        # if comma after first word\n",
    "        elif unknown_name_format.split(\" \")[0][-1] == ',':\n",
    "            pattern = re.compile(r\"(?P<last_name>\\w+,)\\s(((?P<middle_initial>\\w+.|\\w+)\\s)|\\b)((?P<first_name>\\w+))|\\b\")\n",
    "\n",
    "        else:\n",
    "            pattern = re.compile(r\"(?P<first_name>\\w+(.|\\b))\\s*(((?P<middle_initial>\\w+|\\w+.)\\s)|\\b)(?P<last_name>\\w*)\")\n",
    "\n",
    "        reg = re.match(pattern, unknown_name_format)\n",
    "\n",
    "        if reg.group('first_name'):\n",
    "            name_dict['first_name'] = self.remove_punctuation(reg.group('first_name')).capitalize()\n",
    "\n",
    "        if reg.group('middle_initial'):\n",
    "            name_dict['middle_initial'] = self.remove_punctuation(reg.group('middle_initial')).capitalize()\n",
    "\n",
    "        if reg.group('last_name'):\n",
    "            name_dict['last_name'] = self.remove_punctuation(reg.group('last_name')).capitalize()\n",
    "\n",
    "        return name_dict;\n",
    "\n",
    "    def separate_classes_into_list(self, classes):\n",
    "        return re.split(\"\\|\", classes)\n",
    "\n",
    "    def separate_name_from_classes(self, row):\n",
    "        row = row.split(\"  - \")\n",
    "        return row[0], row[1]\n",
    "\n",
    "    # def append_name_to_each_cclass(name, classes):\n",
    "\n",
    "    def import_csv(self, filename):\n",
    "        with open('class.txt') as csvfile:\n",
    "            data = defaultdict(list)\n",
    "            classes_list = []\n",
    "            for row in csvfile:\n",
    "                name, classes = self.separate_name_from_classes(row)\n",
    "                classes = self.separate_classes_into_list(classes)\n",
    "                classes_list.append(classes)\n",
    "                name = self.get_name(name)\n",
    "\n",
    "                # oraganize all classes by last name\n",
    "                # of professor who teaches them\n",
    "                for a_class in classes:\n",
    "                    a_class = a_class.replace('\\n', '')\n",
    "                    prof_name = name['last_name']\n",
    "                    data[prof_name].append(a_class)\n",
    "\n",
    "            return data\n",
    "\n",
    "    def build_classes_list(self, data):\n",
    "        classes = []\n",
    "        for key, a_list in data.items():\n",
    "            for an_item in a_list:\n",
    "                if an_item in classes:\n",
    "                    pass\n",
    "                else:\n",
    "                    classes.append(an_item)\n",
    "        return sorted(classes)\n",
    "\n",
    "    def get_clean_data(self, filename):\n",
    "        # print(entity_resolution_between_list(classes_list, 5))\n",
    "        #     # TODO - see which classes are being resolved and chech that there are no errors\n",
    "\n",
    "        # get the data in a dirty format\n",
    "        # this data is organize is a dict where the key is the professor last name and the \n",
    "        # value is a list of classes that they teach\n",
    "        data_dirty = self.import_csv(filename)\n",
    "\n",
    "        # get a list of classes in a dirty format, the classes in the list are not distinct and\n",
    "        # will need resolving later\n",
    "        classes_list_dirty = self.build_classes_list(data_dirty)\n",
    "    #     print(classes_list_dirty)\n",
    "\n",
    "        # get a dictionary of key value pairs where the key value maps to a \n",
    "        # resolution between class_a -> class_b\n",
    "        classes_dict_resolved = self.entity_resolution(classes_list_dirty, 5)\n",
    "    #     print(classes_dict_resolved)\n",
    "\n",
    "        # now resolve the classes associated with each professor\n",
    "        # by passing in the existing mapping and a list of classes\n",
    "        data_resolved = {}\n",
    "        for professor, classes in data_dirty.items():\n",
    "            data_resolved[professor] = self.resolve_list(classes, classes_dict_resolved)\n",
    "    #     print(data_resolved)\n",
    "\n",
    "        # now that we've resolved the data, it's time to\n",
    "        # correct the spelling for each item\n",
    "\n",
    "        # first lets load wordnet words into memory\n",
    "        wordnet_dict = self.load_wordnet_into_mem('WordNet.csv')\n",
    "\n",
    "        # now lets correct the spelling of each sentence\n",
    "        data_spell_checked = data_resolved\n",
    "        for name, classes in data_resolved.items():\n",
    "            classes_spell_checked = []\n",
    "            for a_class_dirty in classes:\n",
    "                classes_spell_checked.append(self.correct_sentence_spelling(a_class_dirty))\n",
    "            data_spell_checked[name] = classes_spell_checked\n",
    "\n",
    "    #     print(data_spell_checked)\n",
    "\n",
    "        # next lets fixed the capitalization of each word in the sentences\n",
    "        data_capitalized_correctly = data_spell_checked\n",
    "        for name, classes in data_spell_checked.items():\n",
    "            classes_capitalized_correctly = []\n",
    "            for a_class_dirty in classes:\n",
    "                classes_capitalized_correctly.append(self.fix_sentence_case(a_class_dirty))\n",
    "            data_capitalized_correctly[name] = classes_capitalized_correctly\n",
    "\n",
    "    #     print(data_capitalized_correctly)\n",
    "\n",
    "        # now we have a workable set that we can query from!\n",
    "        data_clean = data_capitalized_correctly\n",
    "        return data_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
